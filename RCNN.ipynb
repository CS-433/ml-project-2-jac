{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from pandas import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"15_first_events.csv\")\n",
    "\n",
    "\n",
    "#maybe we will need to use that\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           # Convert to PyTorch tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize if needed\n",
    "])\n",
    "#Specify the path to your custom dataset\n",
    "custom_dataset_path = '/path/to/your/dataset' #normally ./data/0/ and ./data/1/\n",
    "\n",
    "# Load the custom dataset using ImageFolder\n",
    "custom_dataset = ImageFolder(root=custom_dataset_path, transform=transform)\n",
    "\n",
    "# Create a DataLoader for iterating over batches\n",
    "custom_dataloader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example: Iterate over batches\n",
    "for images, labels in custom_dataloader:\n",
    "    # Your custom processing or training logic here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RCNN, self).__init__()\n",
    "        \n",
    "        self.input_layer=torch.nn.Linear(in_features=500*500*15, out_features=500*500*15)\n",
    "\n",
    "        self.norm=torch.nn.BatchNorm1d()#not sure this is sufficent for batch renormalization\n",
    "\n",
    "        #Three convolutionnal and batch renormalization\n",
    "        self.conv1=torch.nn.Conv1d(in_channels=15, out_channels=64, kernel_size=3, stride=1) #need padding of one normally but not precised\n",
    "        self.relu1=torch.nn.ReLU()\n",
    "        self.norm1=torch.nn.BatchNorm1d()\n",
    "\n",
    "        self.conv2=torch.nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.relu2=torch.nn.ReLU()\n",
    "        self.norm2=torch.nn.BatchNorm1d()\n",
    "\n",
    "        self.conv3=torch.nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.relu3=torch.nn.ReLU()\n",
    "        self.norm3=torch.nn.BatchNorm1d()\n",
    "\n",
    "        #First max pooling\n",
    "        self.max1=torch.nn.MaxPool1d(kernel_size=2,stride=2)\n",
    "\n",
    "        #Three convolutionnal and batch renormalization\n",
    "        self.conv4=torch.nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.relu4=torch.nn.ReLU()\n",
    "        self.norm4=torch.nn.BatchNorm1d()\n",
    "\n",
    "        self.conv5=torch.nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.relu5=torch.nn.ReLU()\n",
    "        self.norm5=torch.nn.BatchNorm1d()\n",
    "\n",
    "        self.conv6=torch.nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.relu6=torch.nn.ReLU()\n",
    "        self.norm6=torch.nn.BatchNorm1d()\n",
    "\n",
    "        #Second maxpool\n",
    "        self.max2=torch.nn.MaxPool1d(stride=2,kernel_size=2)\n",
    "\n",
    "        #Flatten\n",
    "        self.flat1=torch.nn.Flatten()\n",
    "\n",
    "        #fully connected with dropout\n",
    "        self.lin=torch.nn.Linear(in_features=2304, out_features=1024)\n",
    "        self.drop=torch.nn.Dropout(p=0.5)\n",
    "\n",
    "        #LSTM\n",
    "        self.lstm=torch.nn.LSTM(input_size=1024,output_size=512, num_layers=1)\n",
    "\n",
    "        #output\n",
    "        self.output_layer=torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.input_layer(x)\n",
    "        x=self.norm(x)#not sure this is sufficent for batch renormalization\n",
    "\n",
    "        #Three convolutionnal and batch renormalization\n",
    "        x=self.conv1(x) \n",
    "        x=self.relu1(x)\n",
    "        x=self.norm1(x)\n",
    "\n",
    "        x=self.conv2(x)\n",
    "        x=self.relu2(x)\n",
    "        x=self.norm2(x)\n",
    "\n",
    "        x=self.conv3(x)\n",
    "        x=self.relu3(x)\n",
    "        x=self.norm3(x)\n",
    "\n",
    "        #First max pooling\n",
    "        x=self.max1(x)\n",
    "\n",
    "        #Three convolutionnal and batch renormalization\n",
    "        x=self.conv4(x)\n",
    "        x=self.relu4(x)\n",
    "        x=self.norm4(x)\n",
    "\n",
    "        x=self.conv5(x)\n",
    "        x=self.relu5(x)\n",
    "        x=self.norm5(x)\n",
    "\n",
    "        x=self.conv6(x)\n",
    "        x=self.relu6(x)\n",
    "        x=self.norm6(x)\n",
    "\n",
    "        #Second maxpool\n",
    "        x=self.max2(x)\n",
    "\n",
    "        #Flatten\n",
    "        x=self.flat1(x)\n",
    "\n",
    "        #fully connected with dropout\n",
    "        x=self.lin(x)\n",
    "        x=self.drop(x)\n",
    "\n",
    "        #LSTM\n",
    "        x=self.lstm(x)\n",
    "\n",
    "        #output\n",
    "        x=self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, dataset_train, dataset_test, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    @param model: torch.nn.Module\n",
    "    @param criterion: torch.nn.modules.loss._Loss\n",
    "    @param dataset_train: torch.utils.data.DataLoader\n",
    "    @param dataset_test: torch.utils.data.DataLoader\n",
    "    @param optimizer: torch.optim.Optimizer\n",
    "    @param num_epochs: int\n",
    "    \"\"\"\n",
    "    print(\"Starting training\")\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train an epoch\n",
    "        model.train()\n",
    "        for batch_x, batch_y in dataset_train:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        \n",
    "            # Evaluate the network (forward pass)\n",
    "            prediction = model(batch_x)\n",
    "            loss = criterion(prediction, batch_y)\n",
    "\n",
    "            # Compute the gradient\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters of the model with a gradient step\n",
    "            optimizer.step()\n",
    "        \n",
    "\n",
    "        # Test the quality on the test set\n",
    "        model.eval()\n",
    "        accuracies_test = []\n",
    "        for batch_x, batch_y in dataset_test:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "            # Evaluate the network (forward pass)\n",
    "            prediction = model(batch_x)\n",
    "            accuracies_test.append(accuracy(prediction, batch_y))\n",
    "\n",
    "        print(\n",
    "            \"Epoch {} | Test accuracy: {:.5f}\".format(\n",
    "                epoch, sum(accuracies_test).item() / len(accuracies_test)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1000\n",
    "model=RCNN()\n",
    "criterion = (\n",
    "    torch.nn.CrossEntropyLoss()\n",
    ")  # this includes LogSoftmax which executes a logistic transformation\n",
    "\n",
    "optimizer= torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "train(model, criterion, dataset_train, dataset_test, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envADA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
